



# Large Language Models Evaluation



[TOC]



## 1. Reasoning in Large Language Models

### 1.1 Complex Reasoning and Error Analysis
- [2024/08] **Itâ€™s Not Easy Being Wrong: Large Language Models Struggle with Process of Elimination Reasoning** *Balepur N et al. ACL.*[[paper](https://arxiv.org/abs/2311.07532v3)]
  
- [2023/10] **Musr: Testing the limits of chain-of-thought with multistep soft reasoning** *Sprague Z et al. arXiv.*[[paper](https://arxiv.org/pdf/2310.16049)]

### 1.2 Logical and Quantitative Reasoning
- [2024/03] **Don't Trust: Verify--Grounding LLM Quantitative Reasoning with Autoformalization** *Zhou JP et al. arXiv.*[[paper](https://arxiv.org/pdf/2403.18120)] [[code](https://github.com/jinpz/dtv)]
  
- [2024/07] **We-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?** *Qiao R et al. arXiv.*[[paper](https://arxiv.org/pdf/2407.01284)] [[code](https://github.com/We-Math/We-Math)]

## 2. Enhancing Model Robustness 

### 2.1 Factual Accuracy 
- [2024/03] **Long-form factuality in large language models** *Wei J et al. arXiv.*[[paper](https://arxiv.org/pdf/2403.18802.pdf?trk=public_post_comment-text)] [[code](https://github.com/google-deepmind/long-form-factuality)]
  


### 2.2 Robustness to Adversarial Prompts


- [2024/08] **LogicBench: Towards systematic evaluation of logical reasoning ability of large language models.** *Parmar M et al. ACL.*[[paper](https://aclanthology.org/2024.acl-long.739.pdf)]



## 3. Code Generation  

### 3.1 Evaluating Code Generation Accuracy
- [2024/02] **Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation** *Liu J et al. NIPS.*[[paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/43e9d647ccd3e4b7b5baab53f0368686-Paper-Conference.pdf)] [[code](https://github.com/evalplus/evalplus)]





## 4. Human and Machine Evaluation
- [2023/10] **Can large language models explain themselves? a study of llm-generated self-explanations** *Huang S et al. arXiv.*[[paper](https://arxiv.org/pdf/2310.11207)]


- [2023/05] **Can large language models be an alternative to human evaluations?** *Chiang CH et al. arXiv.*[[paper](https://arxiv.org/pdf/2305.01937)]


## 5. Prompt Sensitivity 
- [2023/10] **Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting** *Sclar M et al. arXiv.*[[paper](https://arxiv.org/pdf/2310.11324)]


## 6. Survey
- [2024/03] **A survey on evaluation of large language models** *Chang Y et al. ACM TIST.*[[paper](https://dl.acm.org/doi/pdf/10.1145/3641289)] [[code](https://github.com/MLGroupJLU/LLM-eval-survey)]

